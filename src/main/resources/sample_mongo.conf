source {
  type = "mongo"
  host = "mongo.saswata.com:27017"
  ssm-path = "/some/ssm/prefix/"
  aws-region = "ap-south-1"
  user = "???"
  password = "???"
  database = "the_mongo_db_name"
  collection = "the_coll_name"
  readPreference.name = "secondaryPreferred"
}

sink {
  type = "s3"
  bucket = "data-lake"
  folder = "ingestion/spark/the_mongo_db_name/the_coll_name"
  format = "parquet"
  save_mode = "error"
}

spark {
  app.name = "job_the_db_name_the_table_name"
}

schema {
  time_partition_col = "event_epoch"
  time_partition_col_unit = "us"
  epoch_cols = ["event_epoch"]
  numeric_cols = ["src_latitude", "src_longitude", "dst_longitude", "dst_latitude", "demand_price", "interest_rate", "credit_rate", "number_of_vehicles"]
  bool_cols = ["is_futures_derived"]
}
