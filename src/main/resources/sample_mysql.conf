source {
  type = "jdbc"
  url = "jdbc:mysql://saswata.mysql.com:3306/the_db_name"
  dbtable = "the_db_name.the_table_name"
  ssm-path = "/some/ssm/prefix/"
  aws-region = "ap-south-1"
  user = "???"
  password = "???"
  fetchsize = "20000"
}

sink {
  type = "s3"
  bucket = "data-lake"
  folder = "ingestion/spark/the_db_name/the_table_name"
  format = "parquet"
  save_mode = "error"
}

spark {
  app.name = "job_the_db_name_the_table_name"
}

schema {
  time_partition_col = "insertion_timestamp"
  time_partition_col_unit = "ms"
  epoch_cols = ["insertion_timestamp", "last_updation_timestamp"]
}
